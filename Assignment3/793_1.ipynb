{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "793_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "18987ec2ea794675806045e2317360e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_782377bdfedb4f3d8b787891c5ca36af",
              "IPY_MODEL_70f716c89d1941b6b023a0cd0801d824",
              "IPY_MODEL_b82d213e93c349c3a3f4fbffc169a383"
            ],
            "layout": "IPY_MODEL_d151578d603e4f8388d5ef6663acb51a"
          }
        },
        "782377bdfedb4f3d8b787891c5ca36af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91ce4ec61c8141b6abd9c500e37900fd",
            "placeholder": "​",
            "style": "IPY_MODEL_3afe56c5371e47cc9a69cb06664dd107",
            "value": ""
          }
        },
        "70f716c89d1941b6b023a0cd0801d824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2164706de2394d7abaaf0212a0f2fd17",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f700f2095d464e47b4c8ff1a66e50436",
            "value": 170498071
          }
        },
        "b82d213e93c349c3a3f4fbffc169a383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0667b5cd2ed4265b88a39780374030f",
            "placeholder": "​",
            "style": "IPY_MODEL_6d7626e1db1448b9b7a467690f1119ea",
            "value": " 170499072/? [00:04&lt;00:00, 47643450.43it/s]"
          }
        },
        "d151578d603e4f8388d5ef6663acb51a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91ce4ec61c8141b6abd9c500e37900fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3afe56c5371e47cc9a69cb06664dd107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2164706de2394d7abaaf0212a0f2fd17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f700f2095d464e47b4c8ff1a66e50436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0667b5cd2ed4265b88a39780374030f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d7626e1db1448b9b7a467690f1119ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f8jTVDUTEGY",
        "outputId": "322b6891-72bb-4eab-e189-c2269617d682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install einops\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "from einops import rearrange, reduce, repeat\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self, in_channels: int = 3, patch_size: int = 16, emb_size: int = 768, img_size: int = 224):\n",
        "        self.patch_size = patch_size\n",
        "        super().__init__()\n",
        "        self.projection = nn.Sequential(\n",
        "            # using a conv layer instead of a linear one -> performance gains\n",
        "            nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size),\n",
        "            Rearrange('b e (h) (w) -> b (h w) e'),\n",
        "        )\n",
        "        self.cls_token = nn.Parameter(torch.randn(1,1, emb_size))\n",
        "        self.positions = nn.Parameter(torch.randn((img_size // patch_size) **2 + 1, emb_size))\n",
        "\n",
        "        \n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        b, _, _, _ = x.shape\n",
        "        x = self.projection(x)\n",
        "        cls_tokens = repeat(self.cls_token, '() n e -> b n e', b=b)\n",
        "        # prepend the cls token to the input\n",
        "        x = torch.cat([cls_tokens, x], dim=1)\n",
        "        # add position embedding\n",
        "        x += self.positions\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, emb_size: int = 768, num_heads: int = 8, dropout: float = 0):\n",
        "        super().__init__()\n",
        "        self.emb_size = emb_size\n",
        "        self.num_heads = num_heads\n",
        "        # fuse the queries, keys and values in one matrix\n",
        "        self.qkv = nn.Linear(emb_size, emb_size * 3)\n",
        "        self.att_drop = nn.Dropout(dropout)\n",
        "        self.projection = nn.Linear(emb_size, emb_size)\n",
        "        \n",
        "    def forward(self, x : Tensor, mask: Tensor = None) -> Tensor:\n",
        "        # split keys, queries and values in num_heads\n",
        "        qkv = rearrange(self.qkv(x), \"b n (h d qkv) -> (qkv) b h n d\", h=self.num_heads, qkv=3)\n",
        "        queries, keys, values = qkv[0], qkv[1], qkv[2]\n",
        "        # sum up over the last axis\n",
        "        energy = torch.einsum('bhqd, bhkd -> bhqk', queries, keys) # batch, num_heads, query_len, key_len\n",
        "        if mask is not None:\n",
        "            fill_value = torch.finfo(torch.float32).min\n",
        "            energy.mask_fill(~mask, fill_value)\n",
        "            \n",
        "        scaling = self.emb_size ** (1/2)\n",
        "        att = F.softmax(energy, dim=-1) / scaling\n",
        "        att = self.att_drop(att)\n",
        "        # sum up over the third axis\n",
        "        out = torch.einsum('bhal, bhlv -> bhav ', att, values)\n",
        "        out = rearrange(out, \"b h n d -> b n (h d)\")\n",
        "        out = self.projection(out)\n",
        "        return out\n",
        "\n",
        "class ResidualAdd(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "        \n",
        "    def forward(self, x, **kwargs):\n",
        "        res = x\n",
        "        x = self.fn(x, **kwargs)\n",
        "        x += res\n",
        "        return x\n",
        "\n",
        "class FeedForwardBlock(nn.Sequential):\n",
        "    def __init__(self, emb_size: int, expansion: int = 4, drop_p: float = 0.):\n",
        "        super().__init__(\n",
        "            nn.Linear(emb_size, expansion * emb_size),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(drop_p),\n",
        "            nn.Linear(expansion * emb_size, emb_size),\n",
        "        )\n",
        "\n",
        "class TransformerEncoderBlock(nn.Sequential):\n",
        "    def __init__(self,\n",
        "                 emb_size: int = 768,\n",
        "                 drop_p: float = 0.,\n",
        "                 forward_expansion: int = 4,\n",
        "                 forward_drop_p: float = 0.,\n",
        "                 ** kwargs):\n",
        "        super().__init__(\n",
        "            ResidualAdd(nn.Sequential(\n",
        "                nn.LayerNorm(emb_size),\n",
        "                MultiHeadAttention(emb_size, **kwargs),\n",
        "                nn.Dropout(drop_p)\n",
        "            )),\n",
        "            ResidualAdd(nn.Sequential(\n",
        "                nn.LayerNorm(emb_size),\n",
        "                FeedForwardBlock(\n",
        "                    emb_size, expansion=forward_expansion, drop_p=forward_drop_p),\n",
        "                nn.Dropout(drop_p)\n",
        "            )\n",
        "            ))\n",
        "\n",
        "class TransformerEncoder(nn.Sequential):\n",
        "    def __init__(self, depth: int = 12, **kwargs):\n",
        "        super().__init__(*[TransformerEncoderBlock(**kwargs) for _ in range(depth)])\n",
        "\n",
        "class ClassificationHead(nn.Sequential):\n",
        "    def __init__(self, emb_size: int = 768, n_classes: int = 1000):\n",
        "        super().__init__(\n",
        "            Reduce('b n e -> b e', reduction='mean'),\n",
        "            nn.LayerNorm(emb_size), \n",
        "            nn.Linear(emb_size, n_classes))\n",
        "\n",
        "class ViT(nn.Sequential):\n",
        "    def __init__(self,     \n",
        "                in_channels: int = 3,\n",
        "                patch_size: int = 16,\n",
        "                emb_size: int = 768,\n",
        "                img_size: int = 224,\n",
        "                depth: int = 12,\n",
        "                n_classes: int = 1000,\n",
        "                **kwargs):\n",
        "        super().__init__(\n",
        "            PatchEmbedding(in_channels, patch_size, emb_size, img_size),\n",
        "            TransformerEncoder(depth, emb_size=emb_size, **kwargs),\n",
        "            ClassificationHead(emb_size, n_classes)\n",
        "        )"
      ],
      "metadata": {
        "id": "eH7EK72zUwGN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(ViT(1,16,768,32,5,2), (1, 32, 32), device='cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8CyXFikV_c_",
        "outputId": "4f3b1f0e-e6fc-4700-93c7-f2304be9c1b9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 768, 2, 2]         197,376\n",
            "         Rearrange-2               [-1, 4, 768]               0\n",
            "    PatchEmbedding-3               [-1, 5, 768]               0\n",
            "         LayerNorm-4               [-1, 5, 768]           1,536\n",
            "            Linear-5              [-1, 5, 2304]       1,771,776\n",
            "           Dropout-6              [-1, 8, 5, 5]               0\n",
            "            Linear-7               [-1, 5, 768]         590,592\n",
            "MultiHeadAttention-8               [-1, 5, 768]               0\n",
            "           Dropout-9               [-1, 5, 768]               0\n",
            "      ResidualAdd-10               [-1, 5, 768]               0\n",
            "        LayerNorm-11               [-1, 5, 768]           1,536\n",
            "           Linear-12              [-1, 5, 3072]       2,362,368\n",
            "             GELU-13              [-1, 5, 3072]               0\n",
            "          Dropout-14              [-1, 5, 3072]               0\n",
            "           Linear-15               [-1, 5, 768]       2,360,064\n",
            "          Dropout-16               [-1, 5, 768]               0\n",
            "      ResidualAdd-17               [-1, 5, 768]               0\n",
            "        LayerNorm-18               [-1, 5, 768]           1,536\n",
            "           Linear-19              [-1, 5, 2304]       1,771,776\n",
            "          Dropout-20              [-1, 8, 5, 5]               0\n",
            "           Linear-21               [-1, 5, 768]         590,592\n",
            "MultiHeadAttention-22               [-1, 5, 768]               0\n",
            "          Dropout-23               [-1, 5, 768]               0\n",
            "      ResidualAdd-24               [-1, 5, 768]               0\n",
            "        LayerNorm-25               [-1, 5, 768]           1,536\n",
            "           Linear-26              [-1, 5, 3072]       2,362,368\n",
            "             GELU-27              [-1, 5, 3072]               0\n",
            "          Dropout-28              [-1, 5, 3072]               0\n",
            "           Linear-29               [-1, 5, 768]       2,360,064\n",
            "          Dropout-30               [-1, 5, 768]               0\n",
            "      ResidualAdd-31               [-1, 5, 768]               0\n",
            "        LayerNorm-32               [-1, 5, 768]           1,536\n",
            "           Linear-33              [-1, 5, 2304]       1,771,776\n",
            "          Dropout-34              [-1, 8, 5, 5]               0\n",
            "           Linear-35               [-1, 5, 768]         590,592\n",
            "MultiHeadAttention-36               [-1, 5, 768]               0\n",
            "          Dropout-37               [-1, 5, 768]               0\n",
            "      ResidualAdd-38               [-1, 5, 768]               0\n",
            "        LayerNorm-39               [-1, 5, 768]           1,536\n",
            "           Linear-40              [-1, 5, 3072]       2,362,368\n",
            "             GELU-41              [-1, 5, 3072]               0\n",
            "          Dropout-42              [-1, 5, 3072]               0\n",
            "           Linear-43               [-1, 5, 768]       2,360,064\n",
            "          Dropout-44               [-1, 5, 768]               0\n",
            "      ResidualAdd-45               [-1, 5, 768]               0\n",
            "        LayerNorm-46               [-1, 5, 768]           1,536\n",
            "           Linear-47              [-1, 5, 2304]       1,771,776\n",
            "          Dropout-48              [-1, 8, 5, 5]               0\n",
            "           Linear-49               [-1, 5, 768]         590,592\n",
            "MultiHeadAttention-50               [-1, 5, 768]               0\n",
            "          Dropout-51               [-1, 5, 768]               0\n",
            "      ResidualAdd-52               [-1, 5, 768]               0\n",
            "        LayerNorm-53               [-1, 5, 768]           1,536\n",
            "           Linear-54              [-1, 5, 3072]       2,362,368\n",
            "             GELU-55              [-1, 5, 3072]               0\n",
            "          Dropout-56              [-1, 5, 3072]               0\n",
            "           Linear-57               [-1, 5, 768]       2,360,064\n",
            "          Dropout-58               [-1, 5, 768]               0\n",
            "      ResidualAdd-59               [-1, 5, 768]               0\n",
            "        LayerNorm-60               [-1, 5, 768]           1,536\n",
            "           Linear-61              [-1, 5, 2304]       1,771,776\n",
            "          Dropout-62              [-1, 8, 5, 5]               0\n",
            "           Linear-63               [-1, 5, 768]         590,592\n",
            "MultiHeadAttention-64               [-1, 5, 768]               0\n",
            "          Dropout-65               [-1, 5, 768]               0\n",
            "      ResidualAdd-66               [-1, 5, 768]               0\n",
            "        LayerNorm-67               [-1, 5, 768]           1,536\n",
            "           Linear-68              [-1, 5, 3072]       2,362,368\n",
            "             GELU-69              [-1, 5, 3072]               0\n",
            "          Dropout-70              [-1, 5, 3072]               0\n",
            "           Linear-71               [-1, 5, 768]       2,360,064\n",
            "          Dropout-72               [-1, 5, 768]               0\n",
            "      ResidualAdd-73               [-1, 5, 768]               0\n",
            "           Reduce-74                  [-1, 768]               0\n",
            "        LayerNorm-75                  [-1, 768]           1,536\n",
            "           Linear-76                    [-1, 2]           1,538\n",
            "================================================================\n",
            "Total params: 35,639,810\n",
            "Trainable params: 35,639,810\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.61\n",
            "Params size (MB): 135.96\n",
            "Estimated Total Size (MB): 139.57\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from torch.utils.data import random_split,Dataset\n",
        "from torchvision.datasets import MNIST,CIFAR10\n",
        "from torchvision.transforms import Compose,ToTensor,Normalize,RandomHorizontalFlip,RandomRotation, RandomVerticalFlip, RandomApply\n",
        "\n",
        "\n",
        "class TinyCifar(Dataset):\n",
        "    def __init__(self,args,train):\n",
        "        self.train = train\n",
        "        random.seed(args.seed)\n",
        "        if args.normalise=='standard':\n",
        "            mean,std = [0.485, 0.456, 0.406],[0.229, 0.224, 0.225]\n",
        "        elif args.normalise=='constant':\n",
        "            mean,std = (0,),(255.0,)\n",
        "        else:\n",
        "            raise ValueError\n",
        "        \n",
        "        self.test_transforms = Compose([ToTensor(),Normalize(mean,std)])\n",
        "        self.train_transforms =  Compose([ToTensor(),Normalize(mean,std)])\n",
        "        self.augment_transforms = Compose([RandomHorizontalFlip(),RandomVerticalFlip(),RandomRotation(-10,10)])\n",
        "\n",
        "        data = CIFAR10(root=\"cifar/\",train=True,download=True,transform=self.train_transforms)\n",
        "        tiny_data = {}\n",
        "        self.new_data = []\n",
        "        if self.train:\n",
        "            for label in range(0,10):\n",
        "                tiny_data[label] = [x for x in data if x[1]==label]\n",
        "            \n",
        "            print(len(tiny_data[0]))\n",
        "            for label in range(0,10):\n",
        "                self.new_data.extend(random.sample(tiny_data[label],500))\n",
        "\n",
        "            random.shuffle(self.new_data)\n",
        "            assert len(self.new_data)==5000\n",
        "        else:\n",
        "            self.test = CIFAR10(root=\"cifar/\",train=False,transform=self.test_transforms)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.train:\n",
        "            img,y = self.new_data[index]\n",
        "            img = self.augment_transforms(img)\n",
        "            return (img,y)\n",
        "        else:\n",
        "            img,y = self.test[index]\n",
        "            return (img,y)\n",
        "    \n",
        "    def __len__(self):\n",
        "        if self.train:\n",
        "            return 5000\n",
        "        else:\n",
        "            return 10000\n",
        "        \n"
      ],
      "metadata": {
        "id": "xRAC6FRuZXNB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist(args):\n",
        "    if args.normalise=='standard':\n",
        "        mean,std = (0.1307,), (0.3081,)\n",
        "    elif args.normalise=='constant':\n",
        "        mean,std = (0,),(255.0,)\n",
        "    else:\n",
        "        raise ValueError\n",
        "\n",
        "\n",
        "    transforms = Compose([ToTensor(),Normalize(mean,std)])\n",
        "    data = MNIST(root=\"mnist/\",train=True,download=True,transform=transforms)\n",
        "    test = MNIST(root=\"mnist/\",train=False,transform=transforms)\n",
        "    train,val = random_split(data,[50000,10000],generator=torch.Generator().manual_seed(args.seed))\n",
        "\n",
        "    print(\"Train : {}, Validation : {}, Test : {} \".format(len(train),len(val),len(test)))\n",
        "\n",
        "    train = torch.utils.data.DataLoader(train,batch_size=args.batch,shuffle=True)    \n",
        "    val = torch.utils.data.DataLoader(val,batch_size=args.batch,shuffle=True)    \n",
        "    test = torch.utils.data.DataLoader(test,batch_size=32,shuffle=True)  \n",
        "    for x,y in train:\n",
        "        print(type(x),type(y),x.shape,y.shape)\n",
        "        break\n",
        "\n",
        "    return train,val,test\n",
        "\n",
        "def load_cifar(args):\n",
        "    if args.normalise=='standard':\n",
        "        mean,std = [0.485, 0.456, 0.406],[0.229, 0.224, 0.225]\n",
        "    elif args.normalise=='constant':\n",
        "        mean,std = (0,),(255.0,)\n",
        "    else:\n",
        "        raise ValueError\n",
        "\n",
        "\n",
        "    test_transforms = Compose([ToTensor(),Normalize(mean,std)])\n",
        "    train_transforms =  Compose([ToTensor(),Normalize(mean,std)])\n",
        "\n",
        "    data = CIFAR10(root=\"cifar/\",train=True,download=True,transform=train_transforms)\n",
        "    test = CIFAR10(root=\"cifar/\",train=False,transform=test_transforms)\n",
        "    train,val = random_split(data,[42000,8000],generator=torch.Generator().manual_seed(args.seed))\n",
        "\n",
        "    print(\"Train : {}, Validation : {}, Test : {} \".format(len(train),len(val),len(test)))\n",
        "\n",
        "    train = torch.utils.data.DataLoader(train,batch_size=args.batch,shuffle=True)    \n",
        "    val = torch.utils.data.DataLoader(val,batch_size=args.batch,shuffle=True)    \n",
        "    test = torch.utils.data.DataLoader(test,batch_size=32,shuffle=True)  \n",
        "    for x,y in train:\n",
        "        print(type(x),type(y),x.shape,y.shape)\n",
        "        break\n",
        "\n",
        "    return train,val,test\n",
        "\n",
        "    pass\n",
        "\n",
        "def load_tinycifar(args):\n",
        "    data = TinyCifar(args,train=True)\n",
        "    test = TinyCifar(args,train=False)\n",
        "    train,val = random_split(data,[4200,800],generator=torch.Generator().manual_seed(args.seed))\n",
        "\n",
        "    print(\"Train : {}, Validation : {}, Test : {} \".format(len(train),len(val),len(test)))\n",
        "\n",
        "    train = torch.utils.data.DataLoader(train,batch_size=args.batch,shuffle=True)    \n",
        "    val = torch.utils.data.DataLoader(val,batch_size=args.batch,shuffle=True)    \n",
        "    test = torch.utils.data.DataLoader(test,batch_size=32,shuffle=True)  \n",
        "    for x,y in train:\n",
        "        print(type(x),type(y),x.shape,y.shape)\n",
        "        break\n",
        "\n",
        "    return train,val,test\n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "hm3OPVZiY7oj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class temp:\n",
        "        def __init__(self):\n",
        "            self.normalise = 'standard'\n",
        "            self.seed = 10\n",
        "            self.layers = 2\n",
        "            self.expt = 2\n",
        "            self.batch = 128\n",
        "            self.epochs= 75\n",
        "            self.early = 10\n",
        "            self.dropout = False\n",
        "            self.reg = False\n",
        "            self.dropout_rate = 0.0\n",
        "            self.activation = 'relu'\n",
        "            self.lr = 0.01\n",
        "            self.hid = 128\n",
        "            self.scratch = True\n",
        "            self.name = None \n",
        "            self.device = None\n",
        "    \n",
        "args = temp() \n",
        "args.name = 'Expt{}_l{}_ep{}_early{}_reg{}_dr{}_rate_{}_act{}_hid{}_lr{}_sc{}_bch{}__norm{}_seed{}'.format(args.expt,args.layers,args.epochs,args.early,args.reg,args.dropout,args.dropout_rate,args.activation,args.hid,args.lr,args.scratch,args.batch,args.normalise,args.seed)\n",
        "name = args.name\n",
        "print(name)\n",
        "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "args.save = False\n",
        "\n",
        "\n",
        "def train(model,data_train,data_valid,optimizer,scheduler,args):\n",
        "    losses = []\n",
        "    train_accuracy = []\n",
        "    patience = args.early if args.early > 0 else -1\n",
        "    no_improvement = 0\n",
        "    best = 0\n",
        "    for epoch in range(0,args.epochs):\n",
        "        epoch_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for x,y in data_train:\n",
        "            x = x.to(args.device)\n",
        "            y = y.to(args.device)\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(x).type(torch.float32)\n",
        "            loss = torch.nn.functional.nll_loss(pred,y)\n",
        "            loss.backward()\n",
        "            epoch_loss += loss.item()*len(x)\n",
        "            optimizer.step()\n",
        "            _,output = torch.max(pred,dim=1)\n",
        "            correct += (output == y).detach().float().sum().item()\n",
        "            total = total + x.shape[0]\n",
        "\n",
        "        val_loss,val_acc = test(model,data_valid,args)\n",
        "        train_loss = epoch_loss/total\n",
        "        train_acc = correct/total\n",
        "\n",
        "        print(\"Epoch : {} ,Train Acc : {}, Train Loss : {}, Val Acc : {}, Val Loss : {}\".format(epoch,train_acc,train_loss,val_acc,val_loss))\n",
        "        \n",
        "        with open(\"Results/{}/log.txt\".format(args.name),'a') as f:\n",
        "           f.write(\"Epoch : {} ,Train Acc : {}, Train Loss : {}, Val Acc : {}, Val Loss : {}\\n\".format(epoch,train_acc,train_loss,val_acc,val_loss))\n",
        "        \n",
        "        if val_acc > best + 0.01:\n",
        "            best = val_acc\n",
        "            no_improvement = 0\n",
        "            if args.save:\n",
        "                torch.save(model.state_dict(),\"Results/{}/model_best.pth\".format(args.name))\n",
        "\n",
        "        if args.save:\n",
        "            torch.save(model.state_dict(),\"Results/{}/model_{}.pth\".format(args.name,epoch))\n",
        "\n",
        "        no_improvement += 1\n",
        "\n",
        "        if patience > 0 and no_improvement == patience:\n",
        "            break\n",
        "\n",
        "        scheduler.step(val_acc)\n",
        "        train_accuracy.append(train_acc)\n",
        "        losses.append(train_loss)\n",
        "        \n",
        "    return (losses,train_accuracy)\n",
        "\n",
        "def test(model,data,args):\n",
        "    test_loss = 0\n",
        "    test_accuracy = 0\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for x,y in data:\n",
        "            x = x.to(args.device)\n",
        "            y = y.to(args.device)\n",
        "            pred = model(x).type(torch.float32)\n",
        "            loss = torch.nn.functional.nll_loss(pred,y)\n",
        "            _,output = torch.max(pred,dim=1)\n",
        "            correct += (output == y).detach().float().sum().item()\n",
        "            total = total + x.shape[0]\n",
        "\n",
        "        test_accuracy = correct/total\n",
        "        test_loss = loss/total\n",
        "        \n",
        "    \n",
        "    return test_loss, test_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3t8gDaoaIZZ",
        "outputId": "44113937-39d8-458e-c278-da772e6c08ad"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expt2_l2_ep75_early10_regFalse_drFalse_rate_0.0_actrelu_hid128_lr0.01_scTrue_bch128__normstandard_seed10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train,data_valid,data_test = load_cifar(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "18987ec2ea794675806045e2317360e8",
            "782377bdfedb4f3d8b787891c5ca36af",
            "70f716c89d1941b6b023a0cd0801d824",
            "b82d213e93c349c3a3f4fbffc169a383",
            "d151578d603e4f8388d5ef6663acb51a",
            "91ce4ec61c8141b6abd9c500e37900fd",
            "3afe56c5371e47cc9a69cb06664dd107",
            "2164706de2394d7abaaf0212a0f2fd17",
            "f700f2095d464e47b4c8ff1a66e50436",
            "d0667b5cd2ed4265b88a39780374030f",
            "6d7626e1db1448b9b7a467690f1119ea"
          ]
        },
        "id": "W6G2lL2EbLRE",
        "outputId": "1f91a63a-c036-48c1-915d-f9f222993558"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to cifar/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18987ec2ea794675806045e2317360e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting cifar/cifar-10-python.tar.gz to cifar/\n",
            "Train : 42000, Validation : 8000, Test : 10000 \n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'> torch.Size([128, 3, 32, 32]) torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in data_train:\n",
        "    print(x.shape,y.shape)\n",
        "    out = model(x)\n",
        "    print(out.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEy7oFEecHqb",
        "outputId": "cd6feaa0-fed0-4565-83a9-c0ff6c4e7dba"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 3, 32, 32]) torch.Size([128])\n",
            "torch.Size([128, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import os\n",
        "\n",
        "model = ViT(3,32,16,32,2,10)\n",
        "args.lr = 0.00001\n",
        "optimizer = optim.Adam(params=model.parameters(),lr=args.lr,weight_decay=1e-3)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=5,min_lr=1e-5)\n",
        "\n",
        "try:\n",
        "    os.mkdir(\"Results\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    os.mkdir(\"Results/\"+name)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "\n",
        "train(model,data_train,data_valid,optimizer,scheduler,args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "oWR8IDfdcnEj",
        "outputId": "7e3c1e97-cceb-41eb-ce47-60f8d21f4128"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 0 ,Train Acc : 0.17792857142857144, Train Loss : -0.5552880728131249, Val Acc : 0.218375, Val Loss : -9.293136099586263e-05\n",
            "Epoch : 1 ,Train Acc : 0.23107142857142857, Train Loss : -0.8239356306166876, Val Acc : 0.236625, Val Loss : -0.00013070134446024895\n",
            "Epoch : 2 ,Train Acc : 0.23742857142857143, Train Loss : -0.9630529928888594, Val Acc : 0.23275, Val Loss : -0.0001320558221777901\n",
            "Epoch : 3 ,Train Acc : 0.23792857142857143, Train Loss : -1.0624631857190814, Val Acc : 0.231625, Val Loss : -0.00015102683391887695\n",
            "Epoch : 4 ,Train Acc : 0.23947619047619048, Train Loss : -1.139815902414776, Val Acc : 0.231625, Val Loss : -0.0001331451494479552\n",
            "Epoch : 5 ,Train Acc : 0.24183333333333334, Train Loss : -1.20409587483179, Val Acc : 0.23475, Val Loss : -0.00014327761891763657\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-9fc895c15ec4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-97b84a5ef097>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_train, data_valid, optimizer, scheduler, args)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "smI9riMJdMWd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}